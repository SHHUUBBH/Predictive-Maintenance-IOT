{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Predictive Maintenance for Industrial IoT\n",
        "## Step 6: Optional Cloud Deployment\n",
        "\n",
        "This notebook covers:\n",
        "1. Creating a Flask API for model deployment\n",
        "2. Preparing the model for deployment\n",
        "3. Testing the API locally\n",
        "4. Guidelines for cloud deployment (AWS, Azure, GCP)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, request, jsonify\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Step 6.1: Load the Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded from ../src/model_evaluation/best_classification_model.pkl\n",
            "Model type: XGBClassifier\n",
            "Using 20 features for prediction\n",
            "Preprocessing components created\n"
          ]
        }
      ],
      "source": [
        "# Load the best model\n",
        "model_path = \"../src/model_evaluation/best_classification_model.pkl\"\n",
        "\n",
        "# Check if the model file exists\n",
        "if os.path.exists(model_path):\n",
        "    with open(model_path, 'rb') as file:\n",
        "        model = pickle.load(file)\n",
        "    print(f\"Model loaded from {model_path}\")\n",
        "    print(f\"Model type: {type(model).__name__}\")\n",
        "else:\n",
        "    print(f\"Model file not found at {model_path}\")\n",
        "    print(\"For demonstration purposes, we'll create a simple model\")\n",
        "    \n",
        "    # Import necessary libraries\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    \n",
        "    # Create a simple model\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "    print(\"Created a simple RandomForestClassifier for demonstration\")\n",
        "\n",
        "# Define the feature names (these should match the features used during training)\n",
        "# For demonstration, we'll use dummy feature names\n",
        "feature_names = [f\"feature_{i}\" for i in range(20)]\n",
        "print(f\"Using {len(feature_names)} features for prediction\")\n",
        "\n",
        "# Create preprocessing components\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "print(\"Preprocessing components created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Step 6.2: Create a Flask API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API Endpoints:\n",
            "  POST /predict - Make a prediction\n",
            "  GET /health - Check API health\n",
            "  GET / - API documentation\n",
            "\n",
            "Flask app code saved to ../src/deployment/app.py\n",
            "Model saved to ../src/deployment/model.pkl\n",
            "Preprocessor saved to ../src/deployment/preprocessor.pkl\n",
            "Requirements saved to ../src/deployment/requirements.txt\n",
            "Dockerfile saved to ../src/deployment/Dockerfile\n",
            "\n",
            "Deployment files created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create a Flask application\n",
        "app = Flask(\"PredictiveMaintenance\")\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    \"\"\"\n",
        "    Endpoint for making predictions\n",
        "    \n",
        "    Expected JSON format:\n",
        "    {\n",
        "        \"data\": {\n",
        "            \"feature_0\": value,\n",
        "            \"feature_1\": value,\n",
        "            ...\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    Returns:\n",
        "    {\n",
        "        \"prediction\": 0 or 1,\n",
        "        \"probability\": float,\n",
        "        \"status\": \"success\"\n",
        "    }\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get the request data\n",
        "        request_data = request.get_json()\n",
        "        \n",
        "        # Extract the feature values\n",
        "        input_data = request_data['data']\n",
        "        \n",
        "        # Convert to DataFrame\n",
        "        input_df = pd.DataFrame([input_data])\n",
        "        \n",
        "        # Ensure all features are present\n",
        "        for feature in feature_names:\n",
        "            if feature not in input_df.columns:\n",
        "                input_df[feature] = np.nan\n",
        "        \n",
        "        # Select only the required features in the correct order\n",
        "        input_df = input_df[feature_names]\n",
        "        \n",
        "        # Preprocess the data\n",
        "        input_df = input_df.replace('na', np.nan)\n",
        "        input_df = input_df.apply(pd.to_numeric, errors='coerce')\n",
        "        input_imputed = imputer.transform(input_df)\n",
        "        input_scaled = scaler.transform(input_imputed)\n",
        "        \n",
        "        # Make prediction\n",
        "        prediction = int(model.predict(input_scaled)[0])\n",
        "        probability = float(model.predict_proba(input_scaled)[0][1])\n",
        "        \n",
        "        # Return the prediction\n",
        "        return jsonify({\n",
        "            'prediction': prediction,\n",
        "            'probability': probability,\n",
        "            'status': 'success'\n",
        "        })\n",
        "    \n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            'error': str(e),\n",
        "            'status': 'error'\n",
        "        }), 400\n",
        "\n",
        "# Define a health check endpoint\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    \"\"\"\n",
        "    Endpoint for health check\n",
        "    \n",
        "    Returns:\n",
        "    {\n",
        "        \"status\": \"healthy\"\n",
        "    }\n",
        "    \"\"\"\n",
        "    return jsonify({\n",
        "        'status': 'healthy'\n",
        "    })\n",
        "\n",
        "# Define a route for the API documentation\n",
        "@app.route('/', methods=['GET'])\n",
        "def home():\n",
        "    \"\"\"\n",
        "    Home page with API documentation\n",
        "    \n",
        "    Returns:\n",
        "    HTML page with API documentation\n",
        "    \"\"\"\n",
        "    return \"\"\"\n",
        "    <html>\n",
        "        <head>\n",
        "            <title>Predictive Maintenance API</title>\n",
        "            <style>\n",
        "                body { font-family: Arial, sans-serif; margin: 20px; }\n",
        "                h1 { color: #333; }\n",
        "                h2 { color: #666; }\n",
        "                pre { background-color: #f5f5f5; padding: 10px; border-radius: 5px; }\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1>Predictive Maintenance API</h1>\n",
        "            <p>This API provides endpoints for predicting equipment failures.</p>\n",
        "            \n",
        "            <h2>Endpoints</h2>\n",
        "            \n",
        "            <h3>POST /predict</h3>\n",
        "            <p>Make a prediction based on sensor data.</p>\n",
        "            <p>Example request:</p>\n",
        "            <pre>\n",
        "{\n",
        "    \"data\": {\n",
        "        \"feature_0\": 0.5,\n",
        "        \"feature_1\": -1.2,\n",
        "        ...\n",
        "    }\n",
        "}\n",
        "            </pre>\n",
        "            <p>Example response:</p>\n",
        "            <pre>\n",
        "{\n",
        "    \"prediction\": 0,\n",
        "    \"probability\": 0.12345,\n",
        "    \"status\": \"success\"\n",
        "}\n",
        "            </pre>\n",
        "            \n",
        "            <h3>GET /health</h3>\n",
        "            <p>Check if the API is healthy.</p>\n",
        "            <p>Example response:</p>\n",
        "            <pre>\n",
        "{\n",
        "    \"status\": \"healthy\"\n",
        "}\n",
        "            </pre>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "# Print the API endpoints\n",
        "print(\"API Endpoints:\")\n",
        "print(\"  POST /predict - Make a prediction\")\n",
        "print(\"  GET /health - Check API health\")\n",
        "print(\"  GET / - API documentation\")\n",
        "\n",
        "# Note: In a Jupyter notebook, we can't run the Flask app directly\n",
        "# Instead, we'll save the app to a file that can be run separately\n",
        "app_code = \"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from flask import Flask, request, jsonify\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the model\n",
        "with open('model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "# Load the preprocessing components\n",
        "with open('preprocessor.pkl', 'rb') as file:\n",
        "    preprocessor = pickle.load(file)\n",
        "    imputer = preprocessor['imputer']\n",
        "    scaler = preprocessor['scaler']\n",
        "    feature_names = preprocessor['feature_names']\n",
        "\n",
        "# Create the Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        # Get the request data\n",
        "        request_data = request.get_json()\n",
        "        \n",
        "        # Extract the feature values\n",
        "        input_data = request_data['data']\n",
        "        \n",
        "        # Convert to DataFrame\n",
        "        input_df = pd.DataFrame([input_data])\n",
        "        \n",
        "        # Ensure all features are present\n",
        "        for feature in feature_names:\n",
        "            if feature not in input_df.columns:\n",
        "                input_df[feature] = np.nan\n",
        "        \n",
        "        # Select only the required features in the correct order\n",
        "        input_df = input_df[feature_names]\n",
        "        \n",
        "        # Preprocess the data\n",
        "        input_df = input_df.replace('na', np.nan)\n",
        "        input_df = input_df.apply(pd.to_numeric, errors='coerce')\n",
        "        input_imputed = imputer.transform(input_df)\n",
        "        input_scaled = scaler.transform(input_imputed)\n",
        "        \n",
        "        # Make prediction\n",
        "        prediction = int(model.predict(input_scaled)[0])\n",
        "        probability = float(model.predict_proba(input_scaled)[0][1])\n",
        "        \n",
        "        # Return the prediction\n",
        "        return jsonify({\n",
        "            'prediction': prediction,\n",
        "            'probability': probability,\n",
        "            'status': 'success'\n",
        "        })\n",
        "    \n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            'error': str(e),\n",
        "            'status': 'error'\n",
        "        }), 400\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({\n",
        "        'status': 'healthy'\n",
        "    })\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def home():\n",
        "    return \\\"\\\"\\\"\n",
        "    <html>\n",
        "        <head>\n",
        "            <title>Predictive Maintenance API</title>\n",
        "            <style>\n",
        "                body { font-family: Arial, sans-serif; margin: 20px; }\n",
        "                h1 { color: #333; }\n",
        "                h2 { color: #666; }\n",
        "                pre { background-color: #f5f5f5; padding: 10px; border-radius: 5px; }\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1>Predictive Maintenance API</h1>\n",
        "            <p>This API provides endpoints for predicting equipment failures.</p>\n",
        "            \n",
        "            <h2>Endpoints</h2>\n",
        "            \n",
        "            <h3>POST /predict</h3>\n",
        "            <p>Make a prediction based on sensor data.</p>\n",
        "            <p>Example request:</p>\n",
        "            <pre>\n",
        "{\n",
        "    \"data\": {\n",
        "        \"feature_0\": 0.5,\n",
        "        \"feature_1\": -1.2,\n",
        "        ...\n",
        "    }\n",
        "}\n",
        "            </pre>\n",
        "            <p>Example response:</p>\n",
        "            <pre>\n",
        "{\n",
        "    \"prediction\": 0,\n",
        "    \"probability\": 0.12345,\n",
        "    \"status\": \"success\"\n",
        "}\n",
        "            </pre>\n",
        "            \n",
        "            <h3>GET /health</h3>\n",
        "            <p>Check if the API is healthy.</p>\n",
        "            <p>Example response:</p>\n",
        "            <pre>\n",
        "{\n",
        "    \"status\": \"healthy\"\n",
        "}\n",
        "            </pre>\n",
        "        </body>\n",
        "    </html>\n",
        "    \\\"\\\"\\\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000)\n",
        "\"\"\"\n",
        "\n",
        "# Save the Flask app code to a file\n",
        "app_path = \"../src/deployment/app.py\"\n",
        "os.makedirs(os.path.dirname(app_path), exist_ok=True)\n",
        "with open(app_path, 'w') as file:\n",
        "    file.write(app_code)\n",
        "print(f\"\\nFlask app code saved to {app_path}\")\n",
        "\n",
        "# Save the model and preprocessor for deployment\n",
        "model_deployment_path = \"../src/deployment/model.pkl\"\n",
        "preprocessor_path = \"../src/deployment/preprocessor.pkl\"\n",
        "\n",
        "# Save the model\n",
        "with open(model_deployment_path, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "print(f\"Model saved to {model_deployment_path}\")\n",
        "\n",
        "# Save the preprocessor components\n",
        "preprocessor = {\n",
        "    'imputer': imputer,\n",
        "    'scaler': scaler,\n",
        "    'feature_names': feature_names\n",
        "}\n",
        "with open(preprocessor_path, 'wb') as file:\n",
        "    pickle.dump(preprocessor, file)\n",
        "print(f\"Preprocessor saved to {preprocessor_path}\")\n",
        "\n",
        "# Create a requirements.txt file for deployment\n",
        "requirements = \"\"\"\n",
        "flask==2.0.1\n",
        "numpy==1.24.3\n",
        "pandas==2.0.1\n",
        "scikit-learn==1.2.2\n",
        "gunicorn==20.1.0\n",
        "\"\"\"\n",
        "\n",
        "requirements_path = \"../src/deployment/requirements.txt\"\n",
        "with open(requirements_path, 'w') as file:\n",
        "    file.write(requirements)\n",
        "print(f\"Requirements saved to {requirements_path}\")\n",
        "\n",
        "# Create a Dockerfile for containerization\n",
        "dockerfile = \"\"\"\n",
        "FROM python:3.9-slim\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "COPY app.py .\n",
        "COPY model.pkl .\n",
        "COPY preprocessor.pkl .\n",
        "\n",
        "EXPOSE 5000\n",
        "\n",
        "CMD [\"gunicorn\", \"--bind\", \"0.0.0.0:5000\", \"app:app\"]\n",
        "\"\"\"\n",
        "\n",
        "dockerfile_path = \"../src/deployment/Dockerfile\"\n",
        "with open(dockerfile_path, 'w') as file:\n",
        "    file.write(dockerfile)\n",
        "print(f\"Dockerfile saved to {dockerfile_path}\")\n",
        "\n",
        "print(\"\\nDeployment files created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Step 6.3: Testing the API Locally\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample request data:\n",
            "{\n",
            "  \"data\": {\n",
            "    \"feature_0\": -0.8585847814066446,\n",
            "    \"feature_1\": -0.11666854657580962,\n",
            "    \"feature_2\": -1.4632407785115564,\n",
            "    \"feature_3\": -0.2196053076590707,\n",
            "    \"feature_4\": -1.5192069144720377,\n",
            "    \"feature_5\": 0.5648721140285824,\n",
            "    \"feature_6\": 0.5809559739964003,\n",
            "    \"feature_7\": -1.080773249121745,\n",
            "    \"feature_8\": 1.6931610545729905,\n",
            "    \"feature_9\": 1.189935171884811,\n",
            "    \"feature_10\": -0.8311761659111269,\n",
            "    \"feature_11\": -1.9674196071774492,\n",
            "    \"feature_12\": 1.680503763498022,\n",
            "    \"feature_13\": 0.6092984149112326,\n",
            "    \"feature_14\": -1.232858147143944,\n",
            "    \"feature_15\": -0.8028524479662006,\n",
            "    \"feature_16\": -0.409730789441248,\n",
            "    \"feature_17\": 0.11754500127624966,\n",
            "    \"feature_18\": 1.3559341181716527,\n",
            "    \"feature_19\": -0.7789000036547056\n",
            "  }\n",
            "}\n",
            "\n",
            "To test the API locally, follow these steps:\n",
            "1. Open a terminal and navigate to the deployment directory:\n",
            "   cd src/deployment\n",
            "2. Run the Flask app:\n",
            "   python app.py\n",
            "3. Open another terminal and make a request to the API:\n",
            "   curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"feature_0\": 0.5, \"feature_1\": -1.2}}' http://localhost:5000/predict\n",
            "4. Or use a tool like Postman to make requests to the API\n",
            "\n",
            "To run the API in a Docker container:\n",
            "1. Build the Docker image:\n",
            "   docker build -t predictive-maintenance-api .\n",
            "2. Run the Docker container:\n",
            "   docker run -p 5000:5000 predictive-maintenance-api\n",
            "3. Make requests to the API as described above\n"
          ]
        }
      ],
      "source": [
        "# Create a sample request for testing\n",
        "sample_data = {\n",
        "    \"data\": {\n",
        "        feature: np.random.normal() for feature in feature_names\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Sample request data:\")\n",
        "print(json.dumps(sample_data, indent=2))\n",
        "\n",
        "# Note: In a Jupyter notebook, we can't run the Flask app directly\n",
        "# In a real environment, you would run the Flask app and make requests to it\n",
        "print(\"\\nTo test the API locally, follow these steps:\")\n",
        "print(\"1. Open a terminal and navigate to the deployment directory:\")\n",
        "print(\"   cd src/deployment\")\n",
        "print(\"2. Run the Flask app:\")\n",
        "print(\"   python app.py\")\n",
        "print(\"3. Open another terminal and make a request to the API:\")\n",
        "print(\"   curl -X POST -H \\\"Content-Type: application/json\\\" -d '{\\\"data\\\": {\\\"feature_0\\\": 0.5, \\\"feature_1\\\": -1.2}}' http://localhost:5000/predict\")\n",
        "print(\"4. Or use a tool like Postman to make requests to the API\")\n",
        "\n",
        "print(\"\\nTo run the API in a Docker container:\")\n",
        "print(\"1. Build the Docker image:\")\n",
        "print(\"   docker build -t predictive-maintenance-api .\")\n",
        "print(\"2. Run the Docker container:\")\n",
        "print(\"   docker run -p 5000:5000 predictive-maintenance-api\")\n",
        "print(\"3. Make requests to the API as described above\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 6.4: Cloud Deployment Guidelines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Cloud Deployment Guidelines\n",
        "\n",
        "## AWS Deployment\n",
        "\n",
        "### Option 1: AWS Elastic Beanstalk\n",
        "\n",
        "1. Install the AWS CLI and EB CLI\n",
        "   ```\n",
        "   pip install awscli awsebcli\n",
        "   ```\n",
        "\n",
        "2. Configure AWS credentials\n",
        "   ```\n",
        "   aws configure\n",
        "   ```\n",
        "\n",
        "3. Initialize EB application\n",
        "   ```\n",
        "   cd src/deployment\n",
        "   eb init -p python-3.9 predictive-maintenance-api\n",
        "   ```\n",
        "\n",
        "4. Create an environment and deploy\n",
        "   ```\n",
        "   eb create predictive-maintenance-env\n",
        "   ```\n",
        "\n",
        "5. Open the application\n",
        "   ```\n",
        "   eb open\n",
        "   ```\n",
        "\n",
        "### Option 2: AWS Lambda with API Gateway\n",
        "\n",
        "1. Create a Lambda function\n",
        "   - Use the AWS Management Console\n",
        "   - Select Python 3.9 as the runtime\n",
        "   - Upload a ZIP file containing your code and dependencies\n",
        "\n",
        "2. Create an API Gateway\n",
        "   - Create a new REST API\n",
        "   - Create a resource and method (POST)\n",
        "   - Integrate with your Lambda function\n",
        "\n",
        "3. Deploy the API\n",
        "   - Create a stage (e.g., prod)\n",
        "   - Deploy the API to the stage\n",
        "\n",
        "## Azure Deployment\n",
        "\n",
        "### Azure App Service\n",
        "\n",
        "1. Install the Azure CLI\n",
        "   ```\n",
        "   pip install azure-cli\n",
        "   ```\n",
        "\n",
        "2. Login to Azure\n",
        "   ```\n",
        "   az login\n",
        "   ```\n",
        "\n",
        "3. Create a resource group\n",
        "   ```\n",
        "   az group create --name predictive-maintenance-rg --location eastus\n",
        "   ```\n",
        "\n",
        "4. Create an App Service plan\n",
        "   ```\n",
        "   az appservice plan create --name predictive-maintenance-plan --resource-group predictive-maintenance-rg --sku B1 --is-linux\n",
        "   ```\n",
        "\n",
        "5. Create a web app\n",
        "   ```\n",
        "   az webapp create --name predictive-maintenance-api --resource-group predictive-maintenance-rg --plan predictive-maintenance-plan --runtime \"PYTHON:3.9\"\n",
        "   ```\n",
        "\n",
        "6. Deploy your code\n",
        "   ```\n",
        "   az webapp deploy --resource-group predictive-maintenance-rg --name predictive-maintenance-api --src-path ./deployment.zip --type zip\n",
        "   ```\n",
        "\n",
        "## Google Cloud Platform (GCP) Deployment\n",
        "\n",
        "### Google Cloud Run\n",
        "\n",
        "1. Install the Google Cloud SDK\n",
        "   - Follow instructions at https://cloud.google.com/sdk/docs/install\n",
        "\n",
        "2. Initialize the SDK\n",
        "   ```\n",
        "   gcloud init\n",
        "   ```\n",
        "\n",
        "3. Build and push the Docker image\n",
        "   ```\n",
        "   cd src/deployment\n",
        "   gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/predictive-maintenance-api\n",
        "   ```\n",
        "\n",
        "4. Deploy to Cloud Run\n",
        "   ```\n",
        "   gcloud run deploy predictive-maintenance-api --image gcr.io/YOUR_PROJECT_ID/predictive-maintenance-api --platform managed\n",
        "   ```\n",
        "\n",
        "## Production Considerations\n",
        "\n",
        "1. **Security**\n",
        "   - Use HTTPS for all API endpoints\n",
        "   - Implement authentication (API keys, OAuth, etc.)\n",
        "   - Restrict access to the API\n",
        "   - Encrypt sensitive data\n",
        "\n",
        "2. **Monitoring and Logging**\n",
        "   - Set up monitoring for API performance\n",
        "   - Implement logging for debugging\n",
        "   - Set up alerts for errors or unusual activity\n",
        "\n",
        "3. **Scaling**\n",
        "   - Configure auto-scaling based on traffic\n",
        "   - Optimize the API for performance\n",
        "   - Use a load balancer for high-traffic applications\n",
        "\n",
        "4. **CI/CD**\n",
        "   - Set up a CI/CD pipeline for automated testing and deployment\n",
        "   - Use infrastructure as code (e.g., Terraform) for reproducible deployments\n",
        "\n",
        "5. **Backup and Recovery**\n",
        "   - Regularly backup your model and data\n",
        "   - Have a disaster recovery plan\n",
        "   - Test your recovery procedures\n",
        "\"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
